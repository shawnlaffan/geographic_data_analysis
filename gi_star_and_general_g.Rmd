---
title: "gi_star"
author: "Shawn Laffan"
date: "25 March 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load libraries

Load libraries

```{r}
library (rgdal)
library (sp)
library (spdep)
```

## Load your data

Remember to use forward slashes for directory separators.

If you are using a shapefile then set ```source_db``` to equal ```source_dir```.  If using a geodatabase then specify the geodatabase directory name.  If using a geopackage then use the .gpkg file name.

Directories are called "folders" on windows.

Note that rgdal can read geodatabase feature classes and tables, but cannot wite to them. We will use the geopackage format for outputs by default as they can be read by both QGIS and ArcGIS, whle also allowing for long field names.


```{r}

source_dir   = "C:/shawn/lab_data/census_2016"
#  for a shapefile the source db is the source directory
source_db    = paste(source_dir, "census_subset.gdb", sep="/")
source_layer = "SA1_2016_GreaterSydney"
# source_layer = "_test_for_r_centroids"
target_field = "SA1_7dig_long"

output_dir    = source_dir
output_driver = "GPKG"
output_db     = paste(output_dir, "experiment2.gpkg", sep="/")
output_layer_name = paste0("localG_", target_field)
output_overwrite = FALSE

if (file.exists (output_db)) {
  existing_layers = ogrListLayers (output_db)
  if (any(output_layer_name %in% existing_layers)) {
    message (paste("Output layer", output_layer_name, "already exists in", output_db))
    message ("You will need to change the output layer name, set overwrite layer to TRUE, or delete that layer before saving the results (if it is no longer needed)")
  }
}


data = readOGR(dsn = source_db, layer = source_layer)
# if (target_field == "SA1_7dig_long") {
#   #  debug
#   data[[target_field]] = data[[target_field]] / 1000
# }

if (!is.projected(data)) {
  message ("Data are not in a projected coordinate system, but the distance based measures should account for this")
}

data_sf = st_as_sf (data)  #  coerce data into sf class
geom_type = class(data_sf$geometry)
is_poly_data  = any (grepl ("POLY", geom_type))
is_point_data = any (grepl ("POINT", geom_type))

if (!(is_poly_data || is_point_data)) {
  message ("Input data are neither points not polygons, this might not work")
}

```


Plot the data if there are not too many features.   Otherwise it takes a very long time. 

```{r}
#  plotting can take a long time
if (nrow(data) < 3000) {
  spplot (data, zcol=target_field)
} else {
  message ("too many features to plot by default, modify the code to show more")
}

summary (data[[target_field]])

```


Now we run a Gi* analysis.

This requires that we first calculate the spatial weights.

```{r}

distances = c(1000, 2000, 3000, 4000, 5000, 6000, 7000)
output = data  #  should just use the geometry and target_field?
generalGl = list()

generalG.alt = "greater"  #  can also do "less" or "two.sided"

if (is_point_data) {
  centroids = data_sf
} else {
  centroids = st_centroid(data_sf)
}

i = 0
for (target_dist in distances) {
  i = i + 1
  message ("Running distance ", target_dist)
  nbrs = include.self (dnearneigh(centroids, 0, target_dist))
  wts  = nb2listw(nbrs, style="B")
  
  G.gen = globalG.test (data_sf[[target_field]], wts, alternative=generalG.alt)
  generalGl[[as.character(target_dist)]] = G.gen
  
  G.local = localG(data_sf[[target_field]], wts)
  out_fld_name = paste0("G", target_dist)
  output[[out_fld_name]] = as.numeric(G.local)
  # spplot(output, zcol=out_fld_name)
}
```

Now unpack the General G results into a data frame.

```{r}
#  unpack the general G results
#  this is sooooo clunky
generalG = list(
  "distance" = numeric(),
  "Z" = numeric(),
  "p.value"   = numeric(),
  "observed"   = numeric(),
  "expectation" = numeric(),
  "variance"    = numeric(),
  "alternative" = character()
)
#  could re-use distances from above, but this is more standalone
distances = as.numeric (names(generalGl))
i = 0
for (G in generalGl) {
  i = i + 1
  distance = distances[i]
  message (distance)
  generalG[["distance"]] = append(generalG[["distance"]], distance)
  #  simple ones
  generalG[["Z"]] = append (generalG[["Z"]], G[["statistic"]])
  generalG[["p.value"]]   = append (generalG[["p.value"]], G[["p.value"]])
  generalG[["alternative"]] = append (generalG[["alternative"]], G[["alternative"]])
  #  nested comonents
  generalG[["observed"]]    = append (generalG[["observed"]], G[["estimate"]][["Global G statistic"]])
  generalG[["expectation"]] = append (generalG[["expectation"]], G[["estimate"]][["Expectation"]])
  generalG[["variance"]]    = append (generalG[["variance"]], G[["estimate"]][["Variance"]])

}

# for (item in names(generalG)) {
#   names(generalG[[item]]) = c()
# }
df.G = as.data.frame(generalG)
plot (df.G$Z~df.G$distance)


```


Now we need to save the Gi* results to a file.  We will use the geopackage format for the spatial data.
This will fail if you have the output open in a GIS.

```{r}

writeOGR(output, output_db, output_layer_name, driver=output_driver, overwrite_layer = output_overwrite)


```


And now save the general G results.  These can be plotted using excel, or keep going with R if you prefer.

```{r}
out_csv = paste0 (output_dir, "/", output_layer_name, ".csv")
write.csv (df.G, out_csv)
```